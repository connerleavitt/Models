{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Matching "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole idea of getting a computer to compare two seperate strings can seem like an easy task, after all it is extremely easy for us as humans to identify whether or not a word matches another at just a glance. However, this tasks becomes cumbersome when faced with the challenge to compare thousands of addresses to one another. Not only will a normal human mind lose interest but performance may suffer as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy matching isn't anything new. This is a problem that has been solved in a variety of ways (however, you would be suprised at how many people do not know that these tools exists). Due to the fact that fuzzy matching is a asked and answered questions there are packages available that one can pip install and just be a simple \"import and call in\" away from having your own fuzzy match. The python package Fuzzy Wuzzy is an example of one. However I really wanted to dive into how these algorithms work. I wanted to shed a little light on this \"black box\". So, I will attempt to code a fuzzy match from scratch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are a few techniques for comparing two seperate strings and they mostly involve calculating the distance between the two words. Some of these techniques include: Levenshtein distance, Damerau-Levenshtein distance, Bitap, n-gram, BK-tree, Soundex, and Jaro-winkler distance. Many of these algorithms can be found in open sources libraries and are useful tools. I on the other hand want to code one of these from scratch. I chose to implement Levenshtein disantance for a few reasons. From my research it appeared that many of the other models would not be as efficient as levenshteins implementation, or they served a slightly different purpose than what I was trying to achieve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a wonderful article that will walk you through the Levenshtein Algorithm: https://www.cuelogic.com/blog/the-levenshtein-algorithm\n",
    "\n",
    "Here you will find definitions along with the strength and weaknesses of each algorithm: https://www.datasciencecentral.com/profiles/blogs/fuzzy-matching-algorithms-to-help-data-scientists-match-similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with this fuzzy match I want to be able to identify how similar two address are to one another. From my research in application fraud ring behavior individuals commiting fraud on the application level tend to only make minor changes to fields that ussually are distinct such as address and phone number, but to pour over 1,000's of variables to catch one or two individuals is inefficient. So I wnated to build a model to calculate the similarity between two strings and given a threshold would alert me of when two address were oddly similar to another with a specific timeframe (lets say one or two days). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing is first. I will want to read in the data and convert the dataframe into a list so that I can feed into the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>830 Amsterdam ave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2760 Merlin Lake Court</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3011 Magnolia Ave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5219 sw 152 ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>608B N Halifax Ave</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Street\n",
       "0       830 Amsterdam ave\n",
       "1  2760 Merlin Lake Court\n",
       "2       3011 Magnolia Ave\n",
       "3          5219 sw 152 ct\n",
       "4      608B N Halifax Ave"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use pandas to read in the data\n",
    "import pandas as pd\n",
    "#import other important packages \n",
    "import itertools\n",
    "from pprint import pprint\n",
    "#lets set a limit to how many columns are displayed to reduce redundancy \n",
    "pd.options.display.max_columns = 10\n",
    "#read in data\n",
    "address = pd.read_excel(r'C:\\Users\\conner.leavitt\\Desktop\\New_Address.xlsx')\n",
    "address.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is take a list of addresses and compare each address to one another. In order to achieve this I am going to need to duplicate my list so that they can be compared to one another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the datadrame into  a list\n",
    "my_list1 = address['Street'].tolist()\n",
    "my_list2 = address['Street'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I want to do is take the first element from \"my_list1\" and compare that element to every object in \"my_list2\" and once that first element has been compared to every object in \"my_list2\" I want to take the second element in \"my_list1\" and do it all over again and so on and so forth until I have compared every element in \"my_list1\" to \"my_list2\". In other words I need to take the Cartesian Product of my first list and second list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to visualize this for the viewer so I will write out another function to visualize the Linear Algebra I want to perform on my set of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#use itertools.product to visualize the what is going to be happening behind the scenes\n",
    "def compare(a, b):\n",
    "    print('compare({}, {})'.format(a, b))\n",
    "\n",
    "list1 = my_list1\n",
    "list2 = my_list2\n",
    "\n",
    "for a, b in itertools.product(list1, list2):\n",
    "    compare(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a good idea of the task at hand "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy to perform the matrix algebra necessary to calculate the fuzzy match\n",
    "import numpy as np\n",
    "# Define a function that will become the fuzzy match\n",
    "# I decided to use Levenshtein Distance due to the formulas ability to handle string comparisons of two unique lengths\n",
    "def string_match(seq1, seq2, ratio_calc = False):\n",
    "    \"\"\" levenshtein_ratio_and_distance:\n",
    "        Calculates levenshtein distance between two strings.\n",
    "        If ratio_calc = True, the function computes the\n",
    "        levenshtein distance ratio of similarity between two strings\n",
    "        For all i and j, distance[i,j] will contain the Levenshtein\n",
    "        distance between the first i characters of seq1 and the\n",
    "        first j characters of seq2\n",
    "    \"\"\"\n",
    "    # Initialize matrix of zeros\n",
    "    rows = len(seq1)+1\n",
    "    cols = len(seq2)+1\n",
    "    distance = np.zeros((rows,cols),dtype = int)\n",
    "\n",
    "    # Populate matrix of zeros with the indeces of each character of both strings\n",
    "    for i in range(1, rows):\n",
    "        for k in range(1,cols):\n",
    "            distance[i][0] = i\n",
    "            distance[0][k] = k\n",
    "\n",
    "    # loop through the matrix to compute the cost of deletions,insertions and/or substitutions    \n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            if seq1[row-1] == seq2[col-1]:\n",
    "                cost = 0 # If the characters are the same in the two strings in a given position [i,j] then the cost is 0\n",
    "            else:\n",
    "                # In order to align the results with those of the Python Levenshtein package, if we choose to calculate the ratio\n",
    "                # the cost of a substitution is 2. If we calculate just distance, then the cost of a substitution is 1.\n",
    "                if ratio_calc == True:\n",
    "                    cost = 2\n",
    "                else:\n",
    "                    cost = 1\n",
    "            distance[row][col] = min(distance[row-1][col] + 1,      # Cost of deletions\n",
    "                                 distance[row][col-1] + 1,          # Cost of insertions\n",
    "                                 distance[row-1][col-1] + cost)     # Cost of substitutions\n",
    "    if ratio_calc == True:\n",
    "        # Computation of the Levenshtein Distance Ratio\n",
    "        Ratio = round(((len(seq1)+len(seq2)) - distance[row][col]) / (len(seq1)+len(seq2)) * 100, 2)\n",
    "        return Ratio\n",
    "    else:\n",
    "        # print(distance) # Uncomment if you want to see the matrix showing how the algorithm computes the cost of deletions,\n",
    "        # insertions and/or substitutions\n",
    "        # This is the minimum number of edits needed to convert seq1 to seq2\n",
    "        return distance[row][col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you understand the math behind Levenshtein Distance it wasn't to terrible to code with the help of the numpy library. Now that the model is built the next thing we need to do is pass my lists through the the model. In order to this I will create a nested for loop to do this effectively and efficiently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign your list1\n",
    "Test_addrs = my_list1\n",
    "#Assign your List2 and build the nested loop\n",
    "target_addr = my_list2\n",
    "for addr in Test_addrs:\n",
    "    for target in target_addr:\n",
    "        distance = string_match(target, addr, ratio_calc = True)\n",
    "        #print the scores\n",
    "        print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first result should be 100% since the first address in list one and the first address in list are the same address. Perfect! That is how it can get done in a effective and efficent way with lists (because in reality an average person can compare a handful of leases), but it is useful for testing the validity of the model. So below we can test the model with single string objects to see how it is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the strings in seq1 & seq2 to test the calculations\n",
    "seq1 = \"847 Data Drive\"\n",
    "seq2 = \"842 Data Drive\"\n",
    "Distance = string_match(seq1, seq2)\n",
    "ratio = string_match(seq1, seq2, ratio_calc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "92.86\n"
     ]
    }
   ],
   "source": [
    "#print the number of edits required to calculate Levensthein Distance\n",
    "print(Distance)\n",
    "#print the ratio of the Levenshtein Distance (0-100 the higher the number the more similar)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have a functioning model I need to test and get it production ready. So next steps would include:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1) Save Results in a dataframe\n",
    "    2) Maybe create a column for each address and row and have a correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
