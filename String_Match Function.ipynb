{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Matching "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole idea of getting a computer to compare two seperate strings can seem like an easy task, after all it is extremely easy for us as humans to identify whether or not a word matches another at just a glance. However, this tasks becomes cumbersome when faced with the challenge to compare thousands of addresses to one another. Not only will a normal human mind lose interest but performance may suffer as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy matching isn't anything new. This is a problem that has been solved in a variety of ways (however, you would be suprised at how many people do not know that these tools exists). Due to the fact that fuzzy matching is a asked and answered questions there are packages available that one can pip install and just be a simple \"import and call in\" away from having your own fuzzy match. The python package Fuzzy Wuzzy is an example of one. However I really wanted to dive into how these algorithms work. I wanted to shed a little light on this \"black box\". So, I will attempt to code a fuzzy match from scratch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now there are a few techniques for comparing two seperate strings and they mostly involve calculating the distance between the two words. Some of these techniques include: Levenshtein distance, Damerau-Levenshtein distance, Bitap, n-gram, BK-tree, Soundex, and Jaro-winkler distance. Many of these algorithms can be found in open sources libraries and are useful tools. I on the other hand want to code one of these from scratch. I chose to implement Levenshtein disantance for a few reasons. From my research it appeared that many of the other models would not be as efficient as levenshteins implementation, or they served a slightly different purpose than what I was trying to achieve. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outside Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a wonderful article that will walk you through the Levenshtein Algorithm: https://www.cuelogic.com/blog/the-levenshtein-algorithm\n",
    "\n",
    "Here you will find definitions along with the strength and weaknesses of each algorithm: https://www.datasciencecentral.com/profiles/blogs/fuzzy-matching-algorithms-to-help-data-scientists-match-similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So with this fuzzy match I want to be able to identify how similar two address are to one another. From my research in application fraud ring behavior individuals commiting fraud on the application level tend to only make minor changes to fields that ussually are distinct such as address and phone number, but to pour over 1,000's of variables to catch one or two individuals is inefficient. So I wnated to build a model to calculate the similarity between two strings and given a threshold would alert me of when two address were oddly similar to another with a specific timeframe (lets say one or two days). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy to perform the matrix algebra necessary to calculate the fuzzy match\n",
    "import numpy as np\n",
    "# Define a function that will become the fuzzy match\n",
    "# I decided to use Levenshtein Distance due to the formulas ability to handle string comparisons of two unique lengths\n",
    "def string_match(seq1, seq2, ratio_calc = False):\n",
    "    \"\"\" levenshtein_ratio_and_distance:\n",
    "        Calculates levenshtein distance between two strings.\n",
    "        If ratio_calc = True, the function computes the\n",
    "        levenshtein distance ratio of similarity between two strings\n",
    "        For all i and j, distance[i,j] will contain the Levenshtein\n",
    "        distance between the first i characters of seq1 and the\n",
    "        first j characters of seq2\n",
    "    \"\"\"\n",
    "    # Initialize matrix of zeros\n",
    "    rows = len(seq1)+1\n",
    "    cols = len(seq2)+1\n",
    "    distance = np.zeros((rows,cols),dtype = int)\n",
    "\n",
    "    # Populate matrix of zeros with the indeces of each character of both strings\n",
    "    for i in range(1, rows):\n",
    "        for k in range(1,cols):\n",
    "            distance[i][0] = i\n",
    "            distance[0][k] = k\n",
    "\n",
    "    # loop through the matrix to compute the cost of deletions,insertions and/or substitutions    \n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            if seq1[row-1] == seq2[col-1]:\n",
    "                cost = 0 # If the characters are the same in the two strings in a given position [i,j] then the cost is 0\n",
    "            else:\n",
    "                # In order to align the results with those of the Python Levenshtein package, if we choose to calculate the ratio\n",
    "                # the cost of a substitution is 2. If we calculate just distance, then the cost of a substitution is 1.\n",
    "                if ratio_calc == True:\n",
    "                    cost = 2\n",
    "                else:\n",
    "                    cost = 1\n",
    "            distance[row][col] = min(distance[row-1][col] + 1,      # Cost of deletions\n",
    "                                 distance[row][col-1] + 1,          # Cost of insertions\n",
    "                                 distance[row-1][col-1] + cost)     # Cost of substitutions\n",
    "    if ratio_calc == True:\n",
    "        # Computation of the Levenshtein Distance Ratio\n",
    "        Ratio = round(((len(seq1)+len(seq2)) - distance[row][col]) / (len(seq1)+len(seq2)) * 100, 2)\n",
    "        return \"The addresses are {}% similar\".format(Ratio)\n",
    "    else:\n",
    "        # print(distance) # Uncomment if you want to see the matrix showing how the algorithm computes the cost of deletions,\n",
    "        # insertions and/or substitutions\n",
    "        # This is the minimum number of edits needed to convert seq1 to seq2\n",
    "        return \"The strings are {} edits away\".format(distance[row][col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The addresses are 66.67% similar\n",
      "The addresses are 20.69% similar\n",
      "The addresses are 32.0% similar\n"
     ]
    }
   ],
   "source": [
    "Prev_addrs = [\"8847 N Main St\",\n",
    "              \"9763 Peachtree blvd\",\n",
    "              \"543 State steet\"\n",
    "             ]\n",
    "target_addr = \"10 Main St\"\n",
    "for addr in Prev_addrs:\n",
    "    distance = string_match(target_addr, addr, ratio_calc = True)\n",
    "    print (distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1 = \"847 Data Drive\"\n",
    "seq2 = \"842 Data Drive\"\n",
    "Distance = string_match(seq1, seq2)\n",
    "ratio = string_match(seq1, seq2, ratio_calc = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The strings are 1 edits away\n",
      "The addresses are 92.86% similar\n"
     ]
    }
   ],
   "source": [
    "print(Distance)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have a functioning model I need to test and get it production ready. So next steps would include:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1) getting a pandas dataframe of a 100 different address and converting into a list. and comparing the list to a target address. Then testing it on larger data to see how fast and accurate it performs.\n",
    "    2) Finding away to randomly swap the target address once its finished being compared to the list.\n",
    "    3) writing more efficient code but given this was just an excerise I wont worry to much about that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
